<div class="content-intro"><h2><strong>About Anthropic</strong></h2>
<p>Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.</p></div><h2 data-pm-slice="1 1 []"><span class="heading-content"><strong>About the role</strong></span></h2>
<p data-pm-slice="1 1 []">We believe skill with AI is fundamental to human agency. Education Labs builds the paradigms that help people become genuinely more capable—not just more engaged.</p>
<p>This is a new kind of role: part researcher, part product builder, part interaction designer. You'll be the second technical builder on a small team studying how AI transforms human capability—and shipping features based on what we discover. You'll have significant creative license to define what "good" looks like, exploring new interaction patterns rather than optimizing existing ones.</p>
<p>We're skeptical of tutorials, onboarding flows, and engagement metrics. We care about experiences that make users progressively more capable, curious, and empowered over time. This means integrating skill development into product design, using Claude itself as a capability-building partner, and measuring success by how users actually grow.</p>
<p>You'll operate as a one-person technical shop: prototyping new ideas, establishing technical direction, and shipping production-quality features to millions of users. You'll need strong product instincts and clean interface design sensibilities, balanced with comfort in ambiguity and frontier thinking.</p>
<h2><span class="heading-content"><strong>Responsibilities:</strong></span></h2>
<ul>
<li>
<p>Ship features that help users develop real skill with AI—measuring success by capability growth, not time-on-site</p>
</li>
<li>
<p>Architect end-to-end prototypes (front-end and back-end) that test new interaction paradigms, with particular attention to the front-of-the-frontend: motion, polish, and interaction feel</p>
</li>
<li>
<p>Define technical direction for the team—establish patterns others can follow</p>
</li>
<li>
<p>Build relationships across Product, Design, and Research to influence how skill development principles shape Anthropic's broader product strategy</p>
</li>
<li>
<p>Shape team strategy and roadmap—identify the highest-leverage opportunities and build conviction across stakeholders</p>
</li>
<li>
<p>Translate research insights about skill development and human-AI collaboration into shipped product through close collaboration with researchers</p>
</li>
<li>
<p>Document and share your work through clear writing, prototypes, and presentations that influence thinking across the organization</p>
</li>
</ul>
<h2><span class="heading-content"><strong>You may be a good fit if you have:</strong></span></h2>
<p data-pm-slice="1 1 []"><strong>Strong full-stack engineering with design sensibility</strong></p>
<ul>
<li>
<p>6+ years building and shipping web products, with deep expertise across the stack</p>
</li>
<li>
<p>Strong front-end craft: TypeScript/JavaScript, React, CSS—with an eye for interaction design, motion, and visual detail</p>
</li>
<li>
<p>Solid back-end and data pipeline experience: Python, API design, analytics infrastructure</p>
</li>
<li>
<p>A portfolio showcasing innovative interaction designs and high-quality implementations</p>
</li>
<li>
<p>Track record of independently driving features from prototype to production</p>
</li>
</ul>
<p><strong>Deep conviction about human capability</strong></p>
<ul>
<li>
<p>Strong perspective on how technology should enhance human capabilities rather than diminish them</p>
</li>
<li>
<p>Experience or genuine passion for skill development, HCI, developer tools, or products that help people become more capable</p>
</li>
<li>
<p>Skepticism of purely engagement-driven metrics; interest in measuring capability outcomes</p>
</li>
</ul>
<p><strong>Research mindset with product execution</strong></p>
<ul>
<li>
<p>Comfort with ambiguity and exploring undefined problem spaces</p>
</li>
<li>
<p>Ability to rapidly prototype, test with users, and iterate toward production</p>
</li>
<li>
<p>Strong instincts for product design and user experience, even without formal design training</p>
</li>
</ul>
<p><strong>Strategic leadership and coalition building</strong></p>
<ul>
<li>
<p>Experience setting vision, shaping team strategy, and building conviction across cross-functional stakeholders</p>
</li>
<li>
<p>Ability to build productive relationships with Product, Design, Research, and Engineering teams—especially when your team isn't the owner</p>
</li>
<li>
<p>Strong sense of prioritization—knowing what to build now, what to defer, and what to cut</p>
</li>
<li>
<p>Track record of influencing roadmaps and decisions beyond your immediate team</p>
</li>
</ul>
<h3>&nbsp;</h3>
<h2><span class="heading-content"><strong>Strong candidates may also have:</strong></span></h2>
<ul>
<li>
<p>Experience in developer tools, creative tools, learning platforms, or other products where user skill development and mastery matter more than time-on-site</p>
</li>
<li>
<p>Background in learning sciences, cognitive science, HCI, skill acquisition research, or educational psychology (formal or self-directed)</p>
</li>
<li>
<p>Experience with experimentation frameworks, A/B testing, or analytics that measure capability development in production</p>
</li>
<li>
<p>Previous experience in research labs, frontier tech companies, or startups with high autonomy and ambiguity</p>
</li>
<li>
<p>Published writing, talks, or open-source work on skill development, human-AI interaction, or product philosophy</p>
</li>
<li>
<p>Experience building AI-native product experiences or working with LLMs in production contexts</p>
</li>
</ul>
<h3 data-pm-slice="1 1 []"><span class="heading-content">Strong candidates may also have</span></h3>
<ul>
<li>
<p>Background in learning sciences, cognitive science, HCI, or educational psychology</p>
</li>
<li>
<p>Experience in developer tools, creative tools, or learning platforms where mastery matters more than engagement</p>
</li>
<li>
<p>Published writing, talks, or open-source work on skill development or human-AI interaction</p>
</li>
<li>
<p>Experience building AI-native product experiences or working with LLMs in production</p>
</li>
</ul>
<h3><span class="heading-content">What this role is not</span></h3>
<p>This is a hands-on technical role building product features, embedded within a research team. You'll provide technical guidance and help set direction, but this role doesn't involve people management off the bat. If you're looking to immediately transition into engineering management or lead a large team, this likely isn't the right fit.</p>
<p>&nbsp;</p><div class="content-pay-transparency"><div class="pay-input"><div class="description"><p>The annual compensation range for this role is listed below.&nbsp;</p>
<p>For sales roles, the range provided is the role’s On Target Earnings ("OTE") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.</p></div><div class="title">Annual Salary:</div><div class="pay-range"><span>$1</span><span class="divider">&mdash;</span><span>$2 USD</span></div></div></div><div class="content-conclusion"><h2><strong>Logistics</strong></h2>
<p><strong>Education requirements: </strong>We require at least a Bachelor's degree in a related field or equivalent experience.<strong><br><br>Location-based hybrid policy:</strong> Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.</p>
<p><strong data-stringify-type="bold">Visa sponsorship:</strong>&nbsp;We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.</p>
<p><strong>We encourage you to apply even if you do not believe you meet every single qualification.</strong> Not all strong candidates will meet every single qualification as listed.&nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.<br><br><strong data-stringify-type="bold">Your safety matters to us.</strong> To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&nbsp;@anthropic.com&nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit&nbsp;<u data-stringify-type="underline"><a class="c-link c-link--underline" href="http://anthropic.com/careers" target="_blank" data-stringify-link="http://anthropic.com/careers" data-sk="tooltip_parent" data-remove-tab-index="true">anthropic.com/careers</a></u>&nbsp;directly for confirmed position openings.</p>
<h2><strong>How we're different</strong></h2>
<p>We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.</p>
<p>The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.</p>
<h2><strong>Come work with us!</strong></h2>
<p>Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. <strong data-stringify-type="bold">Guidance on Candidates' AI Usage:</strong>&nbsp;Learn about&nbsp;<a class="c-link" href="https://www.anthropic.com/candidate-ai-guidance" target="_blank" data-stringify-link="https://www.anthropic.com/candidate-ai-guidance" data-sk="tooltip_parent">our policy</a>&nbsp;for using AI in our application process</p></div>